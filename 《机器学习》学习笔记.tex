\documentclass{ctexart}

\usepackage{xeCJK}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{newfloat}
\usepackage{setspace}
\usepackage{tikz}
\usepackage{bm}
\usepackage{multirow}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{listings}
\usepackage{framed}
\usepackage[colorlinks,linkcolor=black,anchorcolor=black,citecolor=black,CJKbookmarks=True]{hyperref}
\usepackage{fancyhdr}
\allowdisplaybreaks[4]
\usetikzlibrary{arrows,graphs}
\usetikzlibrary{graphs}
\usetikzlibrary{graphs.standard}
\pagestyle{fancy}
\fancyhead[L]{Machine Learning}
\usetikzlibrary {positioning}
\definecolor {processblue}{cmyk}{0.96,0,0,0}
\setCJKmainfont{STKaiti}

\newtheorem{theorem}{Theorem}

\renewcommand{\algorithmicrequire}{\textbf{Input:}} 
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\begin{document}
			\title{《机器学习》读书笔记}
			\author{黄奕诚}
			\date{}
			\maketitle
			
			\tableofcontents
			\newpage
			\section{绪论}
				\subsection{引言}
					\begin{itemize}
						\item 机器学习致力于研究如何通过计算的手段，利用经验来改善系统自身的性能。
						\item 机器学习研究的主要内容：在计算机上从数据中产生``模型''的算法，即``学习算法''。
					\end{itemize}
				\subsection{基本术语}
					\begin{itemize}
						 \item 数据集（data set）：一组记录的集合
						 \item 示例（instance）/样本（sample）：每条记录，即关于一个事件或对象的描述
						 \item 属性（attribute）/特征（feature）：反映事件或对象在某方面的表现或性质的事项
						 \item 属性值（attribute value）：属性上的取值
						 \item 属性空间（attribute space）/样本空间（sample space）/输入空间：属性张成的空间，记为$\mathcal{X}$
						 \item 特征向量（feature vector）：一个示例（在样本空间对应的坐标向量）
						 \item 学习（learning）/训练（training）：从数据中学得模型的过程
						 \item 训练数据（training data）：训练过程中使用的数据
						 \item 训练样本（training sample）：训练数据中的每个样本
						 \item 训练集（training set）：训练样本组成的集合
						 \item 假设（hypothesis）：对应了关于数据的某种潜在规律的学得模型
						 \item 真实（ground-truth）：潜在规律自身
						 \item 学习器（learner）：学习算法在给定数据和参数空间上的实例化
						 \item 标记（label）：关于示例结果的信息
						 \item 样例（example）：拥有标记信息的示例
						 \item 标记空间（label space）/输出空间：所有标记的集合，记为$\mathcal{Y}$
						 \item 分类（classification）：预测的是离散值的学习任务（二分类$\mathcal{Y}=\{-1,+1\}\textrm{或}\{0,1\}$；三分类$|\mathcal{Y}|>2$）
						 \item 回归（regression）：预测的是连续值的学习任务（$\mathcal{Y}=\mathbb{R}$）
						 \item 测试（testing）：使用学得模型进行预测的过程
						 \item 测试样本（testing sample）：被预测的样本
						 \item 无监督学习（unsupervised learning）：训练数据中没有标记信息的学习任务，代表是聚类（clustering）
						 \item 监督学习（supervised learning）：训练数据中具有标记信息的学习任务，代表是分类和回归
						 \item 泛化（generalization）能力：学得模型适用于新样本的能力
					\end{itemize}
				\subsection{假设空间}
					\begin{itemize}
						\item ``从样例中学习''是一个归纳的过程。
						\item 可以把学习过程看作一个在所有假设组成的空间中进行搜索的过程，搜索目标是找到与训练集``匹配''（fit）的假设。
						\item 假设空间可以表示为一课属性值中通配符逐渐被具体数值取代的树。
						\item 可以用许多策略对假设空间进行搜索，如自顶向下（从一般到特殊）、自底向上（从特殊到一般）。
						\item 可能有多个假设与训练集一致，即存在着一个与训练集一致的``假设集合''，称之为``版本空间''（version space）。
					\end{itemize}
				\subsection{归纳偏好}
					\begin{itemize}
						\item 多个与训练集一致的假设所对应的模型在面临新样本时，可能产生不同的输出。而对于一个具体的学习算法而言，必须要产生一个模型。此时学习算法本身的偏好会起到关键的作用。
						\item 归纳偏好（inductive bias）：机器学习算法在学习过程中对某种类型假设的偏好。
						\item 奥卡姆剃刀（Occam's razor）：若有多个假设与观察一致，则选最简单的那个。【常用的、自然科学研究中最基本的原则】
						\item 设$f$为希望学习的真实目标函数，则基于训练数据$X$的算法$\mathfrak{L}_a$在训练集之外的所有样本上的误差与学习算法无关，即\[\sum_{f}^{}E_{ote}(\mathfrak{L}_a|X,f)=\sum_{f}^{}E_{ote}(\mathfrak{L}_b|X,f)\]``没有免费的午餐''定理（NFL定理）：所有学习算法的期望性相同。
					\end{itemize}
				\subsection{发展历程}
					\begin{enumerate}[1.]
						\item 二十世纪五十年代到七十年代初：``推理期''——赋予机器逻辑推理能力
						\item 二十世纪七十年代中期开始：``知识期''
							\begin{enumerate}[a.]
								\item 机械学习（信息存储与检索）
								\item 示教学习（从指令中学习）
								\item 类比学习（通过观察和发现学习）
								\item 归纳学习（从样例中学习）
									\begin{itemize}
										\item 符号主义学习（决策树、基于逻辑的学习）
										\item 连接主义学习（神经网络）
										\item 统计学习（支持向量机、核方法）
										\item 深度学习
									\end{itemize}
							\end{enumerate}
					\end{enumerate}
				\subsection{应用现状}
					\begin{itemize}
						\item 计算机科学诸多分支学科领域（如计算机视觉、自然语言处理）
						\item 交叉学科（如生物信息学）
						\item 数据挖掘（机器学习领域和数据库领域是数据挖掘的两大支撑）
						\item 人类日常生活（天气预报、搜索引擎、自动驾驶、政治选举等）
						\item 促进人们理解``人类如何学习''
					\end{itemize}
			\section{模型评估与选择}
				\subsection{经验误差与过拟合}
					\begin{itemize}
						\item 设在$m$个样本中有$a$个样本分类错误，则错误率（error rate）为$E=a/m$，精度（accuracy）为$1-a/m$。
						\item 误差（error）：学习器的实际预测输出与样本的真实输出之间的差异。训练误差（training error）/经验误差（empirical error）：学习器在训练集上的误差。泛化误差（generalization error）：学习器在新样本上的误差。想要使泛化误差最小，而新样本未知，所以努力使经验误差最小化。
						\item 过拟合（overfitting）：学习器将训练样本自身的一些特点当作为所有潜在样本都会具有的一般性质。【关键障碍、无法彻底避免】欠拟合（underfitting）：学习器对训练样本的一般性质尚未学好。【较容易克服】若``P$\neq$NP''，过拟合就不可避免。
					\end{itemize}
				\subsection{评估方法}
				
					为了对学习器对泛化误差进行评估，需要使用一个测试集（testing set）来测试学习器对新样本的判别能力，然后以测试集上的测试误差（testing error）作为泛化误差的近似。
					
					若当前只有一个包含$m$个样例的数据集\[D=\{(x_1,y_1),(x_2,y_2),\dots,(x_m,y_m)\}\]，则对其进行适当的处理，从中产生训练集$S$和测试集$T$。
					\subsubsection{留出法}
					
						直接将数据集$D$划分为两个互斥的集合，其中一个作为训练集$S$，另一个作为测试集$T$，即$D=S\cup T,S\cap T=\emptyset$，在$S$上训练出模型后，用$T$来评估其测试误差，作为对泛化误差的估计。
						\begin{itemize}
							\item 划分尽可能保持数据分布的一致性，例如在分类任务中至少要保持样本的类别比例相似（分层采样）。
							\item 一般采用若干次随机划分、重复进行实验评估后取平均值作为评估结果。
							\item $S$和$D$大小权衡没有完美的解决方案，常见做法是2/3$\sim$4/5的训练样本比例。
						\end{itemize}
					\subsubsection{交叉验证法}
						
						将数据集$D$划分为$k$个大小相似的互斥子集，即\[D=D_1\cup D_2\cup\dots\cup D_k,D_i\cup D_j=\emptyset(i\neq j)\]每个子集$D_i$都尽可能保持数据分布的一致性（分层抽样）。然后从中选取$k-1$个子集为训练集，剩下一个子集为测试集。可进行$k$次训练和测试，最终返回$k$个测试结果的均值。也称为``$k$折交叉验证''（$k$-fold cross validation）。
						\begin{itemize}
							\item $k$最常用的取值是10，常用的还有5、20等。
							\item 留一法（Leave-One-Out）不受随机样本划分的影响，评估结果比较准确，但计算开销大。
						\end{itemize}
					\subsubsection{自助法}
						
						以自助采样法（bootstrap sampling）为基础，给定包含$m$个样本的数据集$D$，每次随机从$D$中挑选一个样本，将其拷贝放入$D'$，再将该样本放回初始数据集$D$中。这个过程重复执行$m$次后，得到了包含$m$个样本的数据集$D'$。此时将$D'$用作训练集，$D\backslash D'$用作测试集。
						\begin{itemize}
							\item $D$有约36.8\%的样本未出现在采样数据集$D'$中。
							\item 亦称为``包外估计''（out-of-bag estimate）。
							\item 自助法在数据集较小、难以有效划分训练/测试集时很有用，且能从初始数据集中产生多个不同的训练集。
							\item 因为自助法产生的数据集改变了初始数据集的分布，会引入估计偏差。
						\end{itemize}
					\subsubsection{调参与最终模型}
						\begin{itemize}
							\item 常用的调参做法：对每个参数选定一个范围和变化步长，进行计算开销和性能估计之间的折中。
							\item 在模型选择完成后，学习算法和参数配置已选定，此时用数据集$D$重新训练模型，使用所有$m$个样本，得到最终提交给用户的模型。
						\end{itemize}
				\subsection{性能度量}
					
					给定样例集\[D=\{(\bm{x}_1,y_1),(\bm{x}_2,y_2),\dots,(\bm{x}_m,y_m)\}\]其中$y_i$是示例$\bm{x}_i$的真实标记。要评估学习器$f$的性能，即把学习器预测结果$f(\bm{x})$与真实标记$y$进行比较。
					
					回归任务中最常用的性能度量：``均方误差''（mean squared error）\[E(f;D)=\frac{1}{m}\sum_{i=1}^{m}(f(\bm{x}_i)-y_i)^2\]更一般地，对于数据分布$\mathcal{D}$和概率密度函数$p(\cdot)$，均方误差可描述为\[E(f;\mathcal{D})=\int_{x\sim\mathcal{D}}^{}(f(\bm{x})-y)^2p(\bm{x})d\bm{x}\]对于分类任务——
					\subsubsection{错误率与精度}
						\begin{itemize}
							\item 分类错误率\[E(f;D)=\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}(f(\bm{x}_i)\neq y_i)\]精度\[\mathrm{acc}(f;D)=\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}(f(\bm{x}_i)=y_i)=1-E(f;D)\]
							\item 对于数据分布$\mathcal{D}$和概率密度函数$p(\cdot)$，错误率\[E(f;\mathcal{D})=\int_{x\sim\mathcal{D}}^{}\mathbb{I}(f(\bm{x})\neq y)p(\bm{x})d\bm{x}\]精度\[\mathrm{acc}(f;\mathcal{D})=\int_{x\sim\mathcal{D}}^{}\mathbb{I}(f(\bm{x})=y)p(\bm{x})d\bm{x}=1-E(f;\mathcal{D})\]
						\end{itemize}
					\subsubsection{查准率、查全率与$F1$}
						\begin{center}
							\begin{tabular}{c|c|c}
								\hline
								\multirow{2}*{真实情况} & \multicolumn{2}{|c}{预测结果}\\
								\cline{2-3}
								& 正例 & 反例\\
								\hline
								正例 & $TP$（真正例）& $FN$（假反例）\\
								\hline
								反例 & $FP$（假正例）& $TN$（真反例）\\
								\hline 
							\end{tabular}
						\end{center}
						查准率（precision）\[P=\frac{TP}{TP+FP}\]查全率（recall）\[R=\frac{TP}{TP+FN}\]
						\begin{itemize}
							\item 平衡点（Break-Even Point，BEP）：$R=P$时的取值，数值越高可以认为学习器越优。
							\item $F1$度量\[F1=\frac{2\times P\times R}{P+R}=\frac{2\times TP}{\textrm{样例总数}+TP-TN}\]实际上$F1$是$R$和$P$的调和平均\[\frac{1}{F1}=\frac{1}{2}(\frac{1}{P}+\frac{1}{R})\]
							\item $F_\beta$度量：考虑$R$与$P$的不同偏好，设$\beta$为查全率$R$对查准率$P$的相对重要性，则\[F_\beta=\frac{(1+\beta^2)\times P\times R}{(\beta^2\times P)+R}\]实际上$F_\beta$是加权调和平均\[\frac{1}{F_\beta}=\frac{1}{1+\beta^2}(\frac{1}{P}+\frac{\beta^2}{R})\]
							\item 宏$F1$：在各混淆矩阵上分别计算出各自的$(P_i,R_i)$，再计算平均值：\[\mathrm{macro-}P=\frac{1}{n}\sum_{i=1}^{n}P_i\]\[\mathrm{macro-}R=\frac{1}{n}\sum_{i=1}^{n}R_i\]\[\mathrm{macro-}F1=\frac{2\times\mathrm{macro-}P\times\mathrm{macro-}R}{\mathrm{macro-}P+\mathrm{macro-}R}\]
							\item 微$F1$：先将各混淆矩阵的对应元素进行平均得到四个指标，再基于这些平均值计算$F1$：\[\mathrm{micro-}P=\frac{\overline{TP}}{\overline{TP}+\overline{FP}}\]\[\mathrm{micro-}R=\frac{\overline{TP}}{\overline{TP}+\overline{FN}}\]\[\mathrm{micro-}F1=\frac{2\times\mathrm{micro-}P\times\mathrm{micro-}R}{\mathrm{micro-}P+\mathrm{micro-}R}\]
						\end{itemize}
						\begin{framed}
							$\triangle$ 混淆矩阵介绍：每一列代表了预测类别，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别 ，每一行的数据总数表示该类别的数据实例的数目。例如共有150个样本数据，预测为1、2、3类各50个，分类结束后得到的混淆矩阵为\begin{center}
								\begin{tabular}{|c|c|c|c|c|}
									\hline
									\multicolumn{2}{|c|}{\multirow{2}{*}{}} & \multicolumn{3}{c|}{预测} \\ \cline{3-5} 
									\multicolumn{2}{|c|}{}                  & 类1     & 类2     & 类3    \\ \hline
									\multirow{3}{*}{实际}         & 类1        & 43     & 2      & 0     \\ \cline{2-5} 
									& 类2        & 5      & 45     & 1     \\ \cline{2-5} 
									& 类3        & 2      & 3      & 49    \\ \hline
								\end{tabular}
							\end{center}
						\end{framed}
					\subsubsection{ROC与AUC}
					
						ROC全称是``受试者工作特征''（Receiver Operating Characteristic）曲线。横轴为``假正例率''（$FPR$），纵轴为``真正例率''（$TPR$）。\[TPR=\frac{TP}{TP+FN}\]\[FPR=\frac{FP}{TN+FP}\]
						\begin{itemize}
							\item 现实任务中ROC曲线的绘制方法：给定$m^+$个正例和$m^-$个反例，根据学习器预测结果对样例进行排序，然后把分类阈值设为最大，此时$FPR$和$TPR$都为0.在坐标$(0, 0)$处标记一个点，然后将分类阈值依次设为每个样例的预测值。设当前一个标记点坐标为$(x,y)$，若当前为真正例，则对应标记点坐标为$(x,y+\frac{1}{m^+})$；若当前为假正例，则对应标记点坐标为$(x+\frac{1}{m^-},y)$，然后用线段连接相邻点即得。
							\item AUC（Area Under ROC Curve）即为ROC曲线下各部分的面积之和。设ROC曲线是由坐标为$\{(x_i,y_i)|1\le i\le m\}$的点按序连接而成，则AUC可估算为\[\mathrm{AUC}=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_i)\cdot(y_i+y_{i+1})\]
							\item 给定$m^+$个正例和$m^-$个反例，令$D^+$和$D^-$分别表示正、反例集合，则排序``损失''（loss）定义为\[\ell_{rank}=\frac{1}{m^+m^-}\sum_{\bm{x}^+\in D^+}^{}\sum_{\bm{x}^-\in D^-}^{}\bigg(\mathbb{I}\big(f(\bm{x}^+)<f(\bm{x}^-)\big)+\frac{1}{2}\mathbb{I}\big(f(\bm{x}^+)=f(\bm{x}^-)\big)\bigg)\]它对应ROC曲线之上的面积，有\[\mathrm{AUC}=1-\ell_{rank}\]
						\end{itemize}
					\subsubsection{代价敏感错误率与代价曲线}
						\begin{itemize}
							\item 不同类型的错误可能造成不同损失，所以为错误赋予``非均等代价''（unequal cost）。
							\item 以二分类为例，可以设定一个``代价矩阵''，如下表所示。\begin{center}
								\begin{tabular}{|c|c|c|}
									\hline
									\multirow{2}{*}{真实类别} & \multicolumn{2}{c|}{预测类别} \\ \cline{2-3} 
									& 第0类         & 第1类         \\ \hline
									第0类                   & 0           & $cost_{01}$ \\ \hline
									第1类                   & $cost_{10}$ & 0           \\ \hline
								\end{tabular}	
							\end{center}
							\item ``代价敏感''（cost-sensitive）错误率\[E(f;D;cost)=\frac{1}{m}\bigg(\sum_{\bm{x}_i\in D^+}^{}\mathbb{I}\big(f(\bm{x}_i)\neq y_i\big)\times cost_{01}+\sum_{\bm{x}_i\in D^-}^{}\mathbb{I}\big(f(\bm{x}_i)\neq y_i\big)\times cost_{10}\bigg)\]
							\item 在非均等代价下， ``代价曲线''（cost curve）可以刻画期望总体代价。设$p$是样例为正例的概率。横轴为正例概率代价\[P(+)cost = \frac{p\times cost_{01}}{p\times cost_{01}+(1-p)\times cost_{10}}\]纵轴为取值为$[0,1]$的归一化代价\[cost_{norm}=\frac{\mathrm{FNR}\times p\times cost_{01}+\mathrm{FPR}\times(1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}}\]
							\item 代价曲线的绘制方法：将ROC曲线上的每一点转化为代价平面上的一条线段，取所有线段的下界，围成的面积即为所有条件下学习器的期望总体代价。
						\end{itemize}
				\subsection{比较检验}
					
					本节默认以错误率$\epsilon$为性能度量。
					\subsubsection{假设检验}
						\begin{itemize}
							\item 设一个学习器的泛化错误率为$\epsilon$，在$m$个样本中的测试错误率为$\hat{\epsilon}$，则其被测得测试错误率为$\hat{\epsilon}$的概率为\[P(\hat{\epsilon};\epsilon)=\binom{m}{\hat{\epsilon}\times m}\epsilon^{\hat{\epsilon}\times m}(1-\epsilon)^{m-\hat{\epsilon}\times m}\]它在$\epsilon=\hat{\epsilon}$时最大。
							\item 二项检验：假设$\epsilon\le\epsilon_0$，则在$1-\alpha$的概率内所能观测到的最大错误率为\[\sum_{i=\epsilon_0\times m+1}^{m}\binom{m}{i}\epsilon^i(1-\epsilon)^{m-i}<\alpha\]\[\bar{\epsilon}=\mathrm{max}\epsilon\]若测试错误率$\hat{\epsilon}$小于临界值$\bar{\epsilon}$，则能以$1-\alpha$的置信度认为学习器的泛化错误率不大于$\epsilon_0$，否则假设被拒绝。
							\item $t$检验：若得到了$k$个测试错误率$\hat{\epsilon}_1,\hat{\epsilon}_2,\dots,\hat{\epsilon}_k$，则平均测试错误率$\mu$和方差$\sigma^2$为\[\mu=\frac{1}{k}\sum_{i=1}^{k}\hat{\epsilon}_i\]\[\sigma^2=\frac{1}{k-1}\sum_{i=1}^{k}(\hat{\epsilon}_i-\mu)^2\]它们可看作泛化错误率$\epsilon_0$的独立采样，则变量\[\tau_t=\frac{\sqrt{k}(\mu-\epsilon_0)}{\sigma}\]服从自由度为$k-1$的$t$分布。若$|\mu-\epsilon_0|$位于$[t_{-\alpha/2},t_{\alpha/2}]$内，则接受假设$\mu=\epsilon_0$，否则拒绝该假设。
						\end{itemize}
					\subsubsection{交叉验证$t$检验}
						\begin{itemize}
							\item $k$折交叉验证``成对$t$检验''：对每对结果求差$\Delta_i=\epsilon_i^A-\epsilon_i^B$，若两个学习器性能相同，则差值均值为0。做$t$检验，在显著度$\alpha$下，若\[\tau_t=|\frac{\sqrt{k}\mu}{\sigma}|<t_{\alpha/2,k-1}\]则接受假设。其中$t_{\alpha/2,k-1}$指自由度为$k-1$的$t$分布上尾部累积分布为$\alpha/2$的临界值。
							\item 考虑到交叉验证法等实验估计方法，不同轮次的训练集会有一定程度的重叠，导致测试错误率并不独立。故可采用$5\times2$交叉验证法（5次2折交叉验证）。每次2折交叉验证之前随机将数据打乱，使得5次交叉验证中的数据划分不重复。设$\Delta_i^k$表示第$i$次第$k$上的差值。\[\mu=0.5(\Delta_1^1+\Delta_1^2)\]\[\sigma_i^2=\big(\Delta_i^1-\frac{\Delta_i^1+\Delta_i^2}{2}\big)^2+\big(\Delta_i^2-\frac{\Delta_i^1+\Delta_i^2}{2}\big)^2\]变量\[\tau_t=\frac{\mu}{\sqrt{0.2\sum_{i=1}^{5}\sigma_i^2}}\]服从自由度为5的$t$分布，其双边检验的临界值为$t_{\alpha/2,5}$。
						\end{itemize}
					\subsubsection{McNemar检验}
						
						对于二分类问题，可统计两个学习器A和B的分类结果样本数差别，列出``列联表''（contingency table）\begin{center}
							\begin{tabular}{|c|c|c|}
								\hline
								\multirow{2}{*}{算法B} & \multicolumn{2}{c|}{算法A} \\ \cline{2-3} 
								& 正确          & 错误         \\ \hline
								正确                   & $e_{00}$    & $e_{01}$   \\ \hline
								错误                   & $e_{10}$    & $e_{11}$   \\ \hline
							\end{tabular}
						\end{center}
					
						假设两学习器性能相同，则$e_{01}=e_{10}$，于是$|e_{01}-e_{10}|$服从正态分布，变量\[\tau_{\chi^2}=\frac{(|e_{01}-e_{10}|-1)^2}{e_{01}+e_{10}}\]服从自由度为1的$\chi^2$分布，若其小于临界值$\chi_\alpha^2$则接受假设，否则拒绝假设，较小者性能更优。
					\subsubsection{Friedman检验与Nemenyi后续检验}
						\begin{itemize}
							\item 在多个数据集上比较算法。
							\item 算法排序：使用留出法或交叉验证法得到每个算法在每个数据集上的测试结果，然后在每个数据集上根据测试性能由好到坏排序，序值从1递增，若相同则平分序值。
							\item ``原始Friedman检验''：假定在$N$个数据集上比较$k$个算法，令$r_i$表示第$i$个算法的平均序值，暂不考虑平分序值，则$r_i$均值为$(k+1)/2$，方差为$(k^2-1)/12$。变量\[\tau_{\chi^2}=\frac{k-1}{k}\cdot\frac{12N}{k^2-1}\sum_{i=1}^{k}\big(r_i-\frac{k+1}{2}\big)^2=\frac{12N}{k(k+1)}\bigg(\sum_{i=1}^{k}r_i^2-\frac{k(k+1)^2}{4}\bigg)\]当$k$和$N$都较大时服从自由度为$k-1$的$\chi^2$分布。
							\item Friedman检验：变量\[\tau_F=\frac{(N-1)\tau_{\chi^2}}{N(k-1)-\tau_{\chi^2}}\]服从自由度为$k-1$和$(k-1)(N-1)$的F分布。
							\item Nemenyi检验：若``所有算法的性能相同''这一假设被拒绝，此时计算出平均序值差别的临界值域\[CD=q_{\alpha}\sqrt{\frac{k(k+1)}{6N}}\]若某两个算法的平均序值之差超出了$CD$，则以相应的置信度拒绝``这两个算法性能相同''这一假设。
							\item Friedman检验图：横轴为平均序值，纵轴为各个算法，对每个算法以一个圆点表示平均序值，以圆点为中心的横线段表示临界值域的大小。若两个算法的横线段有交叠，则说明它们没有显著区别，否则可以进行显著比较。
						\end{itemize}
				\subsection{偏差与方差}
					\begin{itemize}
						\item 偏差-方差分解：对学习算法的期望泛化错误率进行拆解。
						\item 学习算法的期望预测\[\bar{f}(\bm{x})=\mathbb{E}_D[f(\bm{x};D)]\]
						\item 使用样本数相同的不同训练集产生的方差\[var(\bm{x})=\mathbb{E}\big[(f(\bm{x};D)-\bar{f}(\bm{x})^2\big]\]
						\item 噪声\[\varepsilon^2=\mathbb{E}_D\big[(y_D-y)^2\big]\]
						\item 偏差（期望输出与真实标记的差别）\[bias^2(\bm{x})=\big(\bar{f}(\bm{x})-y\big)^2\]
						\item 假定$\mathbb{E}_D[y_D-y]=0$，则可通过多项式展开得到\[E(f;D)=\mathbb{E}_D\big[(f(\bm{x};D)-y_D)^2\big]=bias^2(\bm{x})+var(\bm{x})+\varepsilon^2\]泛化误差可分解为偏差、方差与噪声之和。
						\item 偏差：学习算法本身的拟合能力；方差：数据的充分性；噪声：学习问题本身的难度
						\item 偏差-方差窘境（bias-variance dilemma）：训练不足时偏差主导，训练加深时方差主导，训练充足时容易发生过拟合。
					\end{itemize}
			\section{线性模型}
				\subsection{基本形式}
				
					示例$\bm{x}=(x_1;x_2;\dots;x_d)$，其中$x_i$是$\bm{x}$在第$i$个属性上的取值，则线性模型\[f(\bm{x})=w_1x_1+w_2x_2+\dots+w_dx_d+b=\bm{w}^T\bm{x}+b\]
				\subsection{线性回归}
					\begin{itemize}
						\item 一元线性回归的目标\[f(x_i)=wx_i+b,\textrm{ 使得}f(x_i)\simeq y_i\]其中\[(w^*,b^*)=\mathrm{arg}_{(w,b)}\mathrm{min}\sum_{i=1}^{m}(y_i-wx_i-b)^2\]利用``最小二乘法''的最小二乘``参数估计''将$E_{(w,b)}=\sum_{i=1}^{m}(y_i-wx_i-b)^2$对$w$和$b$分别求导并令为零即可得到$w,b$最优解的闭式解\[w=\frac{\sum_{i=1}^{m}y_i(x_i-\bar{x})}{\sum_{i=1}^{m}x_i^2-\frac{1}{m}\big(\sum_{i=1}^{m}x_i\big)^2}\mathrm{\qquad}b=\frac{1}{m}\sum_{i=1}^{m}(y_i-wx_i)\]
						\item 多元线性回归的目标\[f(\bm{x}_i)=\bm{w}^T\bm{x}_i+b,\textrm{ 使得}f(\bm{x}_i)\simeq y_i\]设$\hat{\bm{w}}=(\bm{w};b)$，将数据集$D$表示为一个$m\times(d+1)$大小的矩阵$\bm{X}$\[\bm{X}=\left(\begin{matrix}
						x_{11} & x_{12} & \cdots & x_{1d} & 1 \\
						x_{21} & x_{22} & \cdots & x_{2d} & 1 \\
						\vdots & \vdots & \ddots & \vdots & \vdots \\
						x_{m1} & x_{m2} & \cdots & x_{md} & 1
						\end{matrix}\right)=\left(\begin{matrix}
						\bm{x}_1^T & 1 \\
						\bm{x}_2^T & 1 \\
						\vdots & \vdots \\
						\bm{x}_m^T & 1
						\end{matrix}\right)\]其中\[\hat{\bm{w}}^*=\mathrm{arg}_{\hat{\bm{w}}}\mathrm{min}(\bm{y}-\bm{X\hat{w}})^T(\bm{y}-\bm{X\hat{w}})\]令$E_{\hat{\bm{w}}}=(\bm{y}-\bm{X\hat{w}})^T(\bm{y}-\bm{X\hat{w}})$，对$\bm{\hat{w}}$求导并令为零即$2\bm{X}^T(\bm{X\hat{w}}-\bm{y})=0$即可。若$\bm{X}^T\bm{X}$正定（满秩），则求出$\hat{\bm{w}}^*=(\bm{X}^T\bm{X})^{-1}\bm{X}^T\bm{y}$，此时\[f(\hat{\bm{x}}_i)=\hat{\bm{x}}_i^T(\bm{X}^T\bm{X})^{-1}\bm{X}^T\bm{y}\]若$\bm{X}^T\bm{X}$不满秩，则可能有多解，通过引入正则化由归纳偏好决定。
						\item 广义线性模型：考虑单调可微函数$g(\cdot)$\[y=g^{-1}(\bm{w}^T\bm{x}+b)\]其中$g(\cdot)$称为``联系函数''。
					\end{itemize}
				\subsection{对数几率回归}
					\begin{itemize}
						\item 单位阶跃函数：对于二分类问题将线性回归模型的实值转化为0/1值。其中预测值为临界值零可任意判别\[y=\left\{\begin{aligned}
						0,\quad & z < 0; \\
						0.5,\quad & z = 0; \\
						1,\quad & z > 0;
						\end{aligned}\right.\]
						\item 对数几率函数\[y=\frac{1}{1+e^{-(\bm{w}^T\bm{x}+b)}}\]可化为\[\ln\frac{y}{1-y}=\bm{w}^T\bm{x}+b\]其中$y$可视为$\bm{x}$作为正例的可能性，$1-y$可视为其作为反例的可能性。
						\item 对数几率回归的$\bm{w},b$估计方法：极大似然法。【TODO：细节待学完7.2节极大似然法及梯度下降法再补充】
					\end{itemize}
				\subsection{线性判别分析}
					\begin{itemize}
						\item 思想：设法将样例投影到一条直线上，使得同类样例的投影尽可能接近、异类样例的投影尽可能远离。对于新样本根据其投影到这条直线的投影点位置进行分类。\begin{framed}
							$\triangle$ L2范数（例如欧氏距离）\[\parallel x\parallel_2=\sqrt{\sum_{i=1}^{k}|x_i|^2}\]
						\end{framed}
						\item 目的：使同类样例投影点的协方差（$\bm{w}^T\Sigma_{0}^{}\bm{w}+\bm{w}^T\Sigma_{1}^{}\bm{w}$）尽可能小，使类中心之间的距离（$\parallel\bm{w}^T\bm{\mu}_0-\bm{w}^T\bm{\mu}_1\parallel_2^2$）尽可能大。
						\item 类内散度矩阵\[\bm{S}_w=\Sigma_{0}+\Sigma_{1}=\sum_{\bm{x}\in X_0}^{}(\bm{x}-\bm{\mu}_0)(\bm{x}-\bm{\mu}_0)^T+\sum_{\bm{x}\in X_1}^{}(\bm{x}-\bm{\mu}_1)(\bm{x}-\bm{\mu}_1)^T\]
						\item 类间散度矩阵\[\bm{S}_b=(\bm{\mu}_0-\bm{\mu}_1)(\bm{\mu}_0-\bm{\mu}_1)^T\]
						\item 欲最大化目标（$\bm{S}_b$与$\bm{S}_w$的广义Rayleigh商）\[J=\frac{\parallel\bm{w}^T\bm{\mu}_0-\bm{w}^T\bm{\mu}_1\parallel_2^2}{\bm{w}^T\Sigma_{0}^{}\bm{w}+\bm{w}^T\Sigma_{1}^{}\bm{w}}=\frac{\bm{w}^T(\bm{\mu}_0-\bm{\mu}_1)(\bm{\mu}_0-\bm{\mu}_1)^T\bm{w}}{\bm{w}^T(\Sigma_{0}+\Sigma_{1})\bm{w}}=\frac{\bm{w}^T\bm{S}_b\bm{w}}{\bm{w}^T\bm{S}_w\bm{w}}\]
						\item 确定$\bm{w}$的方法：$J$中的解与$\bm{w}$的长度无关，故令$\bm{w}^T\bm{S}_w\bm{w}=1$，转化为：已知$\bm{w}^T\bm{S}_w\bm{w}=1$求$-\bm{w}\bm{S}_b\bm{w}$的最小值。由拉格朗日乘子法，即$\bm{S}_b\bm{w}=\lambda\bm{S}_w\bm{w}$。又$\bm{S}_b\bm{w}$方向恒为$\bm{\mu}_0-\bm{\mu}_1$，令$\bm{S}_b\bm{w}=\lambda(\bm{\mu}_0-\bm{\mu}_1)$，得\[\bm{w}=\bm{S}_w^{-1}(\bm{\mu}_0-\bm{\mu}_1)\]对$\bm{S}_w$进行奇异值分解$\bm{S}_w=\bm{U\Sigma V}^T$，由$\bm{S}_w^{-1}=\bm{V\Sigma}^{-1}\bm{U}^{-1}$得到$\bm{w}$。
						\begin{framed}
							$\triangle$ 上例用拉格朗日乘子法的计算细节：目标函数为$f(\bm{x})=-\bm{w}\bm{S}_b\bm{w}$，约束方程$g(\bm{x})=\bm{w}^T\bm{S}_w\bm{w}-1=0$。等价于由方程$g(\bm{x})=0$确定的$d-1$维曲面上寻找能使$f(\bm{x})$最小化的点，满足\begin{enumerate}[(1)]
								\item 约束曲面上任意点$\bm{x}$的梯度$\nabla g(\bm{x})$正交于约束曲面
								\item 在最优点$\bm{x}^*$，$f(\bm{x})$在该点的梯度$\nabla f(\bm{x}^*)$正交于约束曲面
							\end{enumerate}于是在最优点$\bm{x}^*$，梯度$\nabla g(\bm{x})$和$\nabla f(\bm{x})$的方向必相同或相反，即存在$\lambda\neq0$使得\[\nabla f(\bm{x}^*)+\lambda\nabla g(\bm{x}^*)=0\]即\[\bm{S}_b\bm{w}=\lambda\bm{S}_w\bm{w}\]
						\end{framed}
						\item LDA推广到多分类任务。假设存在$N$个类，且第$i$类示例数为$m_i$。设$\bm{\mu}$是所有示例的均值向量。全局散度矩阵\[\bm{S}_t=\bm{S}_b+\bm{S}_w=\sum_{i=1}^{m}(\bm{x}_i-\bm{\mu})(\bm{x}_i-\bm{\mu})^T\]类内散度矩阵\[\bm{S}_w=\sum_{i=1}^{N}\bm{S}_{w_i}=\sum_{i=1}^{N}\sum_{\bm{x}\in X_i}^{}(\bm{x}-\bm{\mu}_i)(\bm{x}-\bm{\mu}_i)^T\]类间散度矩阵\[\bm{S}_b=\bm{S}_t-\bm{S}_w=\sum_{i=1}^{N}m_i(\bm{\mu}_i-\bm{\mu})(\bm{\mu}_i-\bm{\mu})^T\]常用实现的优化目标\[\max\limits_{\bm{W}}\frac{\mathrm{tr}(\bm{W}^T\bm{S}_b\bm{W})}{\mathrm{tr}(\bm{W}^T\bm{S}_w\bm{W})}\]可以通过广义特征值$\bm{S}_b\bm{W}=\lambda\bm{S}_w\bm{W}$求解，$\bm{W}$的闭式解为$\bm{S}_w^{-1}\bm{S}_b$的$d'$个最大非零广义特征值对应的特征向量组成的矩阵，有$d'\le N-1$，实现了降维。
					\end{itemize}
				\subsection{多分类学习}
					\begin{itemize}
						\item 基本思路：将多分类任务拆为若干个二分类任务求解，最经典的拆分策略有三种。
						\item 一对一（OvO）：将$N$个类别两两配对，产生$N(N-1)/2$个二分类任务。最终把预测得最多的类别作为分类结果。
						\item 一对其余（OvR）：每次将一个类的样例作为正例，所有其它类的样例作为反例，产生$N$个分类任务。最终若仅有一个分类器预测为正类，则对应的类别标记为最终分类结果，否则考虑各分类器的置信区间，选择置信度最大的类别标记作为分类结果。
						\item 多对多（MvM）：每次将若干个类作为正类，若干个其它类作为反类，可用纠错输出码（ECOC）技术。
						\item ECOC工作过程：\begin{enumerate}[(1)]
							\item 编码（类别划分）：对$N$个类别做$M$次划分，每次划分将一部分类别作为正类、一部分类别作为反类，产生$M$个分类器。
							\item 解码（距离比较）：用$M$个分类器对测试样本进行预测，这些预测标记组成一个编码，计算其与各个类别各自编码的距离，返回距离最小的类别作为分类结果。
						\end{enumerate}
						常用的编码矩阵为二元码和三元码（有停用类）。
						\item 任何两个类别之间的编码距离越远，纠错能力越强，而码长的增加会增大确定最优编码的难度。
					\end{itemize}
				\subsection{类别不平衡问题}
					\begin{itemize}
						\item 类别不平衡（class-imbalance）：分类任务中不同类别的训练样例数目差别很大。以下为类别不平衡学习的策略。
						\item 再缩放（rescaling）：假设``训练集是真实样本总体的无偏采样''，令\[\frac{y'}{1-y'}=\frac{y}{1-y}\times\frac{m^-}{m^+}\]也是代价敏感学习，其中的$m^-/m^+$可用$cost^+/cost^-$代替。
						\item 欠采样（undersampling）/下采样（downsampling）：去除一些正例（反例）使得正、反例数目接近。可用EasyEnsemble算法将反例划分为若干个集合供不同学习器使用，全局上不会丢失重要信息。
						\item 过采样（oversampling）/上采样（upsampling）：增加一些正例（反例）使得正、反例数目接近。可用SMOTE算法对训练集中的正例进行插值。
						\item 阈值移动（threshold-moving）：基于原始训练集学习，在用训练好的分类器进行预测时将``再缩放''中的式子嵌入到决策过程中。
					\end{itemize}
			\section{决策树}
				\subsection{基本流程}
					\begin{itemize}
						\item 决策树的性质：包含一个根结点、若干个内部结点、若干个叶结点，叶结点对应于决策结果，其他每个结点对应于一个属性测试，根结点包含样本全集。从根结点到每个叶结点的路径对应了一个判定测试序列。
						\item 决策树的目的：产生一棵泛化能力强的决策树。
						\item 决策树的基本流程（分治策略）
						\begin{algorithm}
							\caption{TreeGenerate($D,A$)}
							\begin{algorithmic}[1]
								\REQUIRE 训练集$D=\{(\bm{x}_1,y_1),(\bm{x}_2,y_2),\dots,(\bm{x}_m,y_m)\}$;\\属性集$A=\{a_1,a_2,\dots,a_d\}$
								\ENSURE 以node为根结点的一棵决策树
								\STATE 生成结点node; \\
								\IF{$D$中样本全属于同一类别$C$}
								\STATE 将node标记为$C$类叶结点;\\
								\RETURN
								\ENDIF
								\IF{$A=\emptyset$ \OR $D$中样本在$A$上取值相同}
								\STATE 将node标记为叶结点，其类别标记为$D$中样本数最多的类;\\
								\RETURN
								\ENDIF
								\STATE 从$A$中选择最优划分属性$a_*$;\\
								\FOR{$a_*$的每一个值$a_*^v$}
								\STATE 为node生成一个分支;\\
								\STATE 令$D_v$表示$D$中在$a_*$上取值为$a_*^v$的样本子集;\\
								\IF{$D_v$为空}
								\STATE 将分支结点标记为叶结点，其类别标记为$D$中样本数最多的类;\\
								\RETURN
								\ELSE
								\STATE 以$\mathrm{TreeGenerate}(D_v,A\backslash\{a_*\})$为分支结点\\
								\ENDIF
								\ENDFOR
							\end{algorithmic} 
						\end{algorithm}
					\end{itemize}
				\subsection{划分选择}
					
					目的：使决策树的分支结点所包含的样本尽可能属于同一类别，结点的纯度越来越高。
					\subsubsection{信息增益}
						\begin{itemize}
							\item ID3决策树算法以信息增益为准则选择划分属性。
							\item 信息熵（设$D$中共有$\mathcal{Y}$类样本，第$k$类样本所占的比例为$p_k$，值越小则$D$的纯度越高）\[\mathrm{Ent}(D)=-\sum_{k=1}^{|\mathcal{Y}|}p_k\log_2p_k\]
							\item 设离散属性$a$的取值集合为$\{a^1,a^2,\dots,a_V\}$，用$a$对样本集合$D$进行划分，产生$V$个分支结点，第$v$个分支结点包含了$D$中所有在属性$a$上取值为$a^v$的样本，记为$D^v$，于是信息增益（值越大则纯度提升越大）：\[\mathrm{Gain}(D,a)=\mathrm{Ent}(D)-\sum_{v=1}^{V}\frac{|D^v|}{|D|}\mathrm{Ent}(D^v)\]
							\item 最终选择的属性\[a_*=\mathrm{arg}_{a\in A}\mathrm{max}\quad\mathrm{Gain}(D,a)\]
							\item 缺点：对可取值数目较多对属性有所偏好。
						\end{itemize}
					\subsubsection{增益率}
						\begin{itemize}
							\item C4.5决策树算法以增益率为准则选择划分属性。
							\item 增益率\[\mathrm{Gain_ratio}(D,a)=\frac{\mathrm{Gain}(D,a)}{\mathrm{IV}(a)}\]其中$\mathrm{IV}(a)$为属性$a$的``固有值''，可能取值数目越多则通常越大。\[\mathrm{IV}(a)=-\sum_{v=1}^{V}\frac{|D^v|}{|D|}\log_2\frac{|D^v|}{|D|}\]
							\item 缺点：对可取值数目较少的属性有所偏好，所以选择候选划分属性时使用了一个启发式算法：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。
						\end{itemize}
					\subsubsection{基尼指数}
						\begin{itemize}
							\item CART决策树算法以基尼指数（Gini index）为准则选择划分属性。
							\item 基尼值（度量数据集$D$的纯度），反映了从$D$中随机抽取两个样本，其类别标记不一致的概率，值越小则纯度越高。\[\mathrm{Gini}(D)=\sum_{k=1}^{|\mathcal{Y}|}\sum_{k'\neq k}^{}p_kp_{k'}=1-\sum_{k=1}^{|\mathcal{Y}|}p_k^2\]
							\item 属性$a$的基尼指数\[\mathrm{Gini_index}(D,a)=\sum_{v=1}^{V}\frac{|D^v|}{|D|}\mathrm{Gini}(D^v)\]
							\item 最终选择属性\[a_*=\mathrm{arg}_{a\in A}\mathrm{min}\quad\mathrm{Gini_index}(D,a)\]
						\end{itemize}
				\subsection{剪枝处理}
					\begin{itemize}
						\item 目的：去掉一些分支来降低过拟合的风险。
						\item 基本策略之``预剪枝''（prepruning）：在决策树生成过程中对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点。
						\item 基本策略之``后剪枝''（postpruning）：先从训练集生成一棵完整的决策树，然后自底向上对非叶结点考察，若将该结点的子树替换为叶结点能提升决策树的泛化性能，则将该子树替换为叶结点。
						\item 泛化性能评估方法用2.2节的性能评估方法即可，简单地，可以使用留出法并计算错误率（精度）。
					\end{itemize}
					\subsubsection{预剪枝}
						\begin{itemize}
							\item 降低了过拟合的风险。
							\item 显著减少决策树训练和测试时间开销。
							\item 可能因为本身的贪心禁止了那些后续划分使泛化性能显著提升的分支的展开，带来欠拟合的风险。
						\end{itemize}
					\subsubsection{后剪枝}
						\begin{itemize}
							\item 通常比预剪枝决策树保留了更多的分支。
							\item 欠拟合风险很小，泛化性能往往优于预剪枝决策树。
							\item 训练时间比未剪枝或预剪枝决策树大得多。
						\end{itemize}
				\subsection{连续与缺失值}
					\subsubsection{连续值处理}
						\begin{itemize}
							\item 思路：连续属性离散化。
							\item 最简单的策略：二分法（C4.5决策树算法中采用）。
							\item 二分法过程：给定样本集$D$和连续属性$a$，假定$a$在$D$上出现了$n$个不同的取值，将它们从小到大排序，记为$\{a^1,a^2,\dots,a^n\}$，基于划分点$t$划分为子集$D_t^-$和$D_t^+$，前者包含在属性$a$上不大于$t$的样本。我们把每个区间$[a^i,a^{i+1})$的中位点$\frac{a^i+a^{i+1}}{2}$作为候选划分点。
							\item 改造后的信息增益\[\mathrm{Gain}(D,a)=\max\limits_{t\in T_a}\mathrm{Gain}(D,a,t)=\max\limits_{t\in T_a}\big(\mathrm{Ent}(D)-\sum_{\lambda\in\{-,+\}}^{}\frac{|D_t^\lambda|}{|D|}\mathrm{Ent}(D_t^\lambda)\big)\]
							\item 与离散属性的区别：若当前结点划分属性为连续属性，该属性还可以作为其后代结点的划分属性。
						\end{itemize}
					\subsubsection{缺失值处理}
						\begin{itemize}
							\item 策略：利用某个属性$a$上无缺失值样本的信息增益扩放到所有样本的信息增益。（C4.5决策树算法中采用）
							\item 划分属性的选择过程：$\tilde{D}$表示$D$中在属性$a$上没有缺失值的样本子集；$\tilde{D}^v$表示$\tilde{D}$中在属性$a$上取值为$a^v$的样本子集（$1\le v\le V$）；$\tilde{D}_k$表示$\tilde{D}$中属于第$k$类的样本子集（$1\le k\le|\mathcal{Y}$）。为每个样本$\bm{x}$赋予一个权重$w_{\bm{x}}$\begin{align*}
								& \textrm{无缺失值样本的比例：} & \rho=\frac{\sum_{\bm{x}\in\tilde{D}}^{}w_{\bm{x}}}{\sum_{\bm{x}\in D}^{}w_{\bm{x}}}\\
								& \textrm{无缺失值样本中第$k$类的比例：} & \tilde{p}_k=\frac{\sum_{\bm{x}\in\tilde{D}_k}^{}w_{\bm{x}}}{\sum_{\bm{x}\in\tilde{D}}^{}w_{\bm{x}}}\\
								& \textrm{无缺失值样本中在属性$a$上取值为$a^v$的样本的比例：} & \tilde{r}_v=\frac{\sum_{\bm{x}\in\tilde{D^v}}^{}w_{\bm{x}}}{\sum_{\bm{x}\in\tilde{D}}w_{\bm{x}}}
							\end{align*}
							信息增益的推广式\[\mathrm{Gain}(D,a)=\rho\times\mathrm{Gain}(\tilde{D},a)=\rho\times\big(\mathrm{Ent}(\tilde{D})-\sum_{v=1}^{V}\tilde{r}_v\mathrm{Ent}(\tilde{D}^v)\big)\]\[\mathrm{Ent}(\tilde{D})=-\sum_{k=1}^{|\mathcal{Y}|}\tilde{p}_k\log_2\tilde{p}_k\]
							\item 已经划分属性进行样本划分的过程：\begin{itemize}
								\item 若样本$\bm{x}$在$a$上的取值已知，则将其划入与其取值对应的子结点，样本权值在子结点中保持为$w_{\bm{x}}$
								\item 若样本$\bm{x}$在$a$上的取值未知，则将其划入所有子结点，样本权值在与属性值$a^v$对应的子结点中调整为$\tilde{r}_v\cdot w_{\bm{x}}$。
							\end{itemize}
						\end{itemize}
				\subsection{多变量决策树}
					\begin{itemize}
						\item 决策树所形成的分类边界的特点：轴平行。每一段划分都直接对应某个属性取值。当真实分类边界比较复杂时决策树也会相当复杂。
						\item 多变量决策树：非叶结点是一个形如$\sum_{i=1}^{d}w_ia_i=t$的线性分类器。在学习过程中试图建立一个合适的线性分类器。实现了斜划分。
					\end{itemize}
			\section{神经网络}
				\subsection{神经元模型}
					\begin{itemize}
						\item 神经网络的定义：神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体作出对交互反应。
						\item 最基本的成分：神经元模型
						\item M-P神经元模型：神经元接收到来自$n$个其他神经元的输入信号$x_i$，它们各通过带权重$w_i$的连接进行传递，神经元将总输入值$\sum_{i=1}^{n}w_ix_i$与神经元的阈值$\theta$进行比较，得到$\sum_{i=1}^{n}w_ix_i-\theta$，然后通过``激活函数''$f$处理以产生神经元的输出：\[y=f\big(\sum_{i=1}^{n}w_ix_i-\theta\big)\]
						\item 激活函数的模型\begin{itemize}
							\item 阶跃函数（不连续、不光滑）：\[\mathrm{sgn}(x)=\left\{\begin{aligned}
							1, \quad& x\ge0;\\
							0, \quad& x < 0
							\end{aligned}\right.\]
							\item Sigmoid函数（将可能在较大范围内变化的输入值挤压到$(0,1)$输出值范围内）：\[\mathrm{sigmoid}(x)=\frac{1}{1+e^{-x}}\]
						\end{itemize}
					\end{itemize}
				\subsection{感知机与多层网络}
					\begin{enumerate}[1.]
						\item 感知机（Perceptron）：两层神经元，输入层接受外界输入信号后传递给输出层，输出层是M-P神经元，也称为``阈值逻辑单元''\begin{itemize}
							\item 感知机实现逻辑``与''：$w_1=w_2=1,\theta=0$；逻辑``或''：$w_1=w_2=1,\theta=0.5$；逻辑``非''：$w_1=-0.6,w_2=0,\theta=-0.5$。
							\item 将阈值看作固定输入为-1.0的``哑结点''所对应的权重$w_{n+1}$。统一为权重的学习。对训练样例$(\bm{x},y)$，若当前感知机的输出为$\hat{y}$，则其权重调整如下：\[w_i\leftarrow w_i + \Delta w_i\quad\quad\Delta w_i=\eta(y-\hat{y})x_i\]其中$\eta$为$(0,1)$内的小正数，称为学习率。
							\item 感知机只能求解线性可分问题（存在一个线性超平面区分两类模式），对于非线性可分问题会发生振荡（fluctuation）。
						\end{itemize}
						\item 多层前馈神经网络：每层神经元与下一层全互连，不存在同层连接和跨层连接。输入层神经元仅接收输入，隐层与输出层包含功能神经元。
						\item 神经网络的学习过程：根据训练数据来调整神经元之间的连接权以及每个功能神经元的阈值。
					\end{enumerate}
				\subsection{误差逆传播算法}
					\includegraphics[width=\linewidth]{BP}
					\begin{itemize}
						\item 任意参数$v$的更新估计式：$v\leftarrow v+\Delta v$
						\item 目标：最小化训练集$D$上的累积误差\[E=\frac{1}{m}\sum_{k=1}^{m}E_k\]\[E_k=\frac{1}{2}\sum_{j=1}^{l}(\hat{y}_j^k-y_j^k)^2\]
						\item 参数调整原则：梯度下降。例如$\Delta w_{hj}=-\eta\frac{\partial E_k}{\partial w_{hj}}$
						\item 推导方法：参数影响的逐级传递，例如\[\frac{\partial E_k}{\partial w_{hj}}=\frac{\partial E_k}{\partial\hat{y}_j^k}\cdot\frac{\partial\hat{y}_j^k}{\partial\beta_j}\cdot\frac{\partial\beta_j}{\partial w_{hj}}\]Sigmoid函数的性质：$f'(x)=f(x)(1-f(x))$
						\item 各个参数的调整值：\[\Delta w_{hj}=\eta g_jb_h\]\[\Delta\theta_j=-\eta g_j\]\[\Delta v_{ih}=\eta e_hx_i\]\[\Delta\gamma_h=-\eta e_h\]其中\[g_j=\hat{y}_j^k(1-\hat{y}_j^k)(y_j^k-\hat{y}_j^k)\]\[e_h=b_h(1-b_h)\sum_{j=1}^{l}w_{hj}g_j\]
						\item BP算法执行过程：\begin{enumerate}[1.]
							\item 输入：训练集$D=\{(\bm{x}_k,\bm{y}_k)\}_{k=1}^m$和学习率$\eta$
							\item 在$(0,1)$范围内随机初始化网络中所有连接权和阈值
							\item 重复计算$\hat{\bm{y}_k},g_j,e_h$并更新四个参数直到达到停止条件（如训练误差已达到一个很小的值）
							\item 输出：连接权与阈值确定的多层前馈神经网络
						\end{enumerate}
						\item 累积误差逆传播（ABP）算法：省去BP算法对每个样例都更新参数都步骤，而是读取整个训练集一遍后才更新参数，直接针对累积误差最小化。
						\item 缓解过拟合的策略\begin{itemize}
							\item 早停：将数据分成训练集和验证集，若训练集误差降低而验证集误差升高，则停止训练。
							\item 正则化：在误差目标函数中增加一个用于描述网络复杂度的部分。令$\lambda\in(0,1)$，如\[E=\lambda\frac{1}{m}\sum_{k=1}^{m}E_k+(1-\lambda)\sum_{i}^{}w_i^2\]
						\end{itemize}
					\end{itemize}
				\subsection{全局最小与局部极小}
					\begin{itemize}
						\item 神经网络训练过程：在参数空间中寻找一组最优参数使得$E$最小。
						\item 局部极小：对$\bm{w}^*$和$\theta^*$，若存在$\epsilon>0$使得\[\forall(\bm{w};\theta)\in\{(\bm{w};\theta)|\parallel(\bm{w};\theta)-(\bm{w}^*;\theta^*)\parallel\le\epsilon\}\]都有$E(\bm{w};\theta)\ge E(\bm{w}^*;\theta^*)$，则$(\bm{w}^*;\theta^*)$为局部极小解。
						\item 全局最小：对参数空间中任意$(\bm{w};\theta)$都有$E(\bm{w};\theta)\ge E(\bm{w}^*;\theta^*)$，则$(\bm{w}^*;\theta^*)$为全局最小解。
						\item 使用最为广泛的参数寻优方法：梯度下降法（容易找到局部极小）。
						\item 跳出局部极小，进一步接近全局最小的策略：\begin{itemize}
							\item 以多组不同参数值初始化多个神经网络（从多个不同的初始点开始搜索）；
							\item 使用``模拟退火''技术：每一步有一定概率接受比当前解更差的结果，且接受次优解概率随时间推移而逐渐降低；
							\item 使用随机梯度下降（即使陷入局部极小点，计算出来的梯度可能不为零）；
							\item 遗传算法等其它启发式算法。
						\end{itemize}
					\end{itemize}
				\subsection{其他常见神经网络}
					\subsubsection{RBF网络}
						\begin{itemize}
							\item RBF网络（径向基网络）：一种单隐层前馈神经网络。
							\item 隐层激活函数：径向基函数；输出层是对隐层输出的线性组合。
							\item 设$q$为隐层神经元个数，$\bm{c}_i$和$w_i$是第$i$个隐层神经元所对应的中心和权重。径向基函数$\bm{\rho}(\bm{x},\bm{c}_i)$通常定义为样本$\bm{x}$到数据中心$\bm{c}_i$之间欧氏距离的单调函数。常用的高斯径向基函数\[\rho(\bm{x},\bm{c}_i)=e^{-\beta_i\parallel\bm{x}-\bm{c}_i\parallel^2}\]
							\item 训练过程：通过随机采样、聚类等方法确定神经元中心$\bm{c}_i$$\rightarrow$利用BP算法确定参数$w_i$和$\beta_i$
						\end{itemize}
					\subsubsection{ART网络}
						\begin{itemize}
							\item ART网络（自适应谐振网络）：一种竞争学习型无监督神经网络。
							\item 构成：比较层（接收输入样本，传递给识别层）、识别层（每个神经元对应一个模式类，数目也在训练过程中动态增长）、识别阈值、重置模块。
							\item 接收比较层的输入$\rightarrow$识别层神经元相互竞争（向量距离）$\rightarrow$获胜神经元抑制其他识别层神经元的激活$\rightarrow$输入向量与获胜神经元的代表向量相似度大于识别阈值? 则当前输入样本被归为该代表向量所属类别并更新连接权 : 重置模块在识别层增设新神经元，代表向量即为当前输入向量。
							\item 识别阈值高$\rightarrow$输入样本分类数目多且精细；识别阈值低$\rightarrow$输入样本分类数目少且粗略。
							\item 缓解了``可塑性-稳定性窘境''，可进行增量学习或在线学习。
						\end{itemize}
					\subsubsection{SOM网络}
						\begin{itemize}
							\item SOM网络（自组织映射网络）：一种竞争学习型无监督神经网络。
							\item 特点：将高维输入数据映射到低维空间，同时保持输入数据在高维空间的拓扑结构。获胜神经元决定了输入向量在低维中的位置。
							\item 目标：为每个输出层神经元找到合适的权向量，达到拓扑结构的保持。
							\item 训练过程：接收一个训练样本$\rightarrow$每个输出层神经元计算其与自身权向量的距离$\rightarrow$距离最近者获胜（最佳匹配单元）$\rightarrow$最佳匹配单元及其邻近神经元的权向量被调整使得它们与当前输入样本的距离缩小$\rightarrow$不断迭代直到收敛
						\end{itemize}
					\subsubsection{级联相关网络}
						\begin{itemize}
							\item 自适应网络的代表：网络结构也是学习目标之一。
							\item 级联：建立层次连接的层级结构。从仅有输入输出层增加新的隐层神经元。
							\item 相关：通过最大化新神经元的输出与网络误差之间的相关性来训练相关的参数。
							\item 特点：无需设置网络层数、隐层神经元数目，训练速度快，数据较小时易陷入过拟合。
						\end{itemize}
					\subsubsection{Elman网络}
						\begin{itemize}
							\item 最常用的递归神经网络（RNN）之一：可出现环形，有信息反馈，网络在$t$时刻的输出状态与$t$时刻的输入及$t-1$时刻的网络状态都有关。
							\item 结构与多层前馈网络相似，隐层神经元的输出反馈给所有隐层神经元。
							\item 隐层神经元常采用Sigmoid激活函数，网格训练常用推广的BP算法。
						\end{itemize}
					\subsubsection{Bolzmann机}
						\begin{itemize}
							\item 定义了``能量''，能量最小化时网络达理想状态。
							\item 神经元全部为布尔型，神经元两两全连接。设状态向量$\bm{s}\in\{0,1\}^n$表示$n$个神经元的状态。则$\bm{s}$对应的Boltzmann机能量为\[E(\bm{s})=-\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}w_{ij}s_is_j-\sum_{i=1}^{n}\theta_is_i\]
							\item 若神经元以任意不依赖于输入值顺序进行更新，网络最终达到Boltzmann分布（平衡态），此时状态向量$\bm{s}$出现的概率\[P(\bm{s})=\frac{e^{-E(\bm{s})}}{\sum_{\bm{t}}^{}e^{-E(\bm{t})}}\]
							\item 训练过程：将每个训练样本视为一个训练向量，使其出现的概率尽可能大。常用受限Boltzmann机（仅保留显层与隐层的连接）。
							\item 受限Boltzmann机的训练方法：对比散度算法。设显、隐层神经元个数分别为$d,q$，状态向量分别为$\bm{v},\bm{h}$\[P(\bm{v}|\bm{h})=\prod_{i=1}^{d}P(v_i|\bm{h})\quad P(\bm{h}|\bm{v})=\prod_{j=1}^{q}P(h_j|\bm{v})\]
							\item 受限Bolzmann的工作过程：对每个训练样本$\bm{v}$，先计算$P(\bm{h}|\bm{v})$，然后分布采样得到$\bm{h}$，再计算$P(\bm{v}'|\bm{h})$，从$\bm{v}'$产生$\bm{h}$。连接权的更新公式为\[\Delta w=\eta(\bm{v}\bm{h}^T-\bm{v}'\bm{h}^{'T})\]
						\end{itemize}
				\subsection{深度学习}
					\begin{itemize}
						\item 典型的深度学习模型：多隐层神经网络
						\item 多隐层网络训练的手段：无监督逐层训练（预训练+微调）。将大量参数分组，对每组找到局部较优，联系起来进行全局寻优，节省训练开销。
						\item 卷积神经网络（CNN）：待本书主要内容学完后，对于CNN方面将着重学习：\href{https://cs231n.github.io}{CS231n Convolutional Neural Networks for Visual Recognition}
					\end{itemize}
			\section{支持向量机}
				\subsection{间隔与支持向量}
					\begin{itemize}
						\item 划分超平面：\[\bm{w}^{\mathrm{T}}\bm{x}+n=0\]其中$\bm{w}=(w_1;w_2;\dots;w_d)$为法向量，决定方向；$b$为位移项，决定超平面与原点之间的距离。
						\item 样本空间中任意点$\bm{x}$到超平面$(\bm{x},b)$的距离\[r=\frac{|\bm{w}^{\mathrm{T}}+b|}{\parallel\bm{w}\parallel}\]
						\item 若超平面$(\bm{w},b)$能将训练样本正确分类，则对于任意$(\bm{x}_i,y_i)\in D$有\[\left\{\begin{aligned}
							\bm{w}^{\mathrm{T}}\bm{x}_i+b\ge+1, & \quad y_i=+1;\\
							\bm{w}^{\mathrm{T}}\bm{x}_i+b\le-1, & \quad y_i=-1.
							\end{aligned}\right.\]
						\item 支持向量：满足$\bm{w}^{\mathrm{T}}\bm{x}_i+b=\pm1,y_i=\pm1$的距离超平面最近的几个训练样本点。
						\item 间隔：两个异类支持向量到超平面的距离之和：\[\gamma=\frac{2}{\parallel\bm{w}\parallel}\]
						\item 支持向量机（SVM）的基本型：最大化间隔，即最小化$\parallel\bm{w}\parallel^2$\begin{align*}
							& \min\limits_{\bm{w},b}\quad\frac{1}{2}\parallel\bm{w}\parallel^2\\
							& \mathrm{s.t.}\quad y_i(\bm{w}^{\mathrm{T}}\bm{x}_i+b)\ge1, i=1,2,\dots,m.
						\end{align*}
					\end{itemize}
				\subsection{对偶问题}
					
					求解6.1节基本型的一个高效方法：\begin{enumerate}[1.]
						\item 用拉格朗日乘子法得到对偶问题，即对基本型对每条约束添加拉格朗日乘子$a_i\ge0$，得到\[L(\bm{w},b,\bm{\alpha})=\frac{1}{2}\parallel\bm{w}\parallel^2+\sum_{i=1}^{m}\alpha_i(1-y_i(\bm{w}^T\bm{x}_i+b))\]分别令对$\bm{w}$和$b$的偏导数为零再代入消去$\bm{w},b$可得到对偶问题如下：\begin{align*}
							& \max\limits_{\bm{\alpha}}\quad\sum_{i=1}^{m}\alpha_i-\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_i\alpha_jy_iy_j\bm{x}^{\mathrm{T}}\bm{x}_j\\
							& \mathrm{s.t.}\quad\sum_{i=1}^{m}\alpha_iy_i=0\\
							& \alpha_i\ge0,\quad i=1,2,\dots,m.
						\end{align*}
						这样在解出$\bm{\alpha}$后，求出$\bm{w}$和$b$就可以得到模型$f(\bm{x})=\sum_{i=1}^{m}\alpha_iy_i\bm{x}_i^{\mathrm{T}}\bm{x}+b$
						\item 上述过程需满足KKT条件，即要求\[\left\{\begin{aligned}
							\alpha_i\ge0;\\
							y_if(\bm{x}_i)-1\ge0;\\
							\alpha_i(y_if(\bm{x}_i)-1)=0.
						\end{aligned}\right.\]\begin{framed}
							$\triangle$ KKT条件对于上述结论的具体分析过程： 对于不等式约束$g(\bm{x}_i)=1-y_i(\bm{w}^{\mathrm{T}}\bm{x}_i+b)=1-y_if(\bm{x}_i)\le0$，对于$g(\bm{x}_i)<0$的情形，可通过$\nabla f(\bm{x}_i)=0$来获得最优点，等价于在$L(\bm{w},b,\alpha_i)$中对$\alpha_i$置零然后对$\nabla_{\bm{w},b}L(\bm{x}_i,\alpha_i)$置零；对于$g(\bm{x}_i)=0$的情形，类似于拉格朗日乘子法中等式约束的分析，但此时$\nabla f(\bm{x}_i^*)$的方向必与$\nabla g(\bm{x}_i^*)$相反。综上有$\alpha_i g(\bm{x}_i)=0$。由此可转化为在如下约束下最小化拉格朗日函数的问题：\[\left\{\begin{aligned}
							1-y_if(\bm{x}_i)\le0;\\
							\alpha_i\ge0;\\
							\alpha_i(1-y_if(\bm{x}_i))=0.
							\end{aligned}\right.\]
						\end{framed}
						由此可以总结：若$\alpha_i=0$，则该样本不会出现在求和中，没有影响；若$y_if(\bm{x}_i)=1$，则对应的样本点在最大间隔边界上，是支持向量。因此\underline{在支持向量机训练完成后，最终模型仅与支持向量有关。}
						\item 求解第一步最后的对偶问题的方法：二次规划算法（问题规模正比于训练样本数，开销太大）；SMO算法。SMO不断执行以下两个步骤直至收敛：\begin{itemize}
							\item 选取一对需更新的变量$\alpha_i$和$\alpha_j$；
							\item 固定$\alpha_i$和$\alpha_j$以外的参数，求解对偶模型中获得更新后的$\alpha_i$和$\alpha_j$。
						\end{itemize}
						选择参数的启发式方法：\underline{使选取的两变量所对应样本之间的间隔最大}。（对它们进行更新一般会带给目标函数值更大的变化）仅考虑$\alpha_i,\alpha_j$时，因为有\[\alpha_iy_i+\alpha_jy_j=-\sum_{k\neq i,j}^{}\alpha_ky_k,\quad \alpha_i\ge0,\alpha_j\ge0\]可以消去$\alpha_j$得到单变量二次规划问题，仅有的约束是$\alpha_i\ge0$。
						\item 确定偏移项$b$的方法：对于所有支持向量$(\bm{x}_s,y_s),s\in S$都有$y_sf(\bm{x}_s)=1$即\[y_s\bigg(\sum_{i\in S}^{}\alpha_iy_i\bm{x}_i^{\mathrm{T}}\bm{x}_s+b\bigg)=1\]现实任务中一般使用所有支持向量求解的平均值：\[b=\frac{1}{|S|}\sum_{s\in S}^{}\bigg(1/y_s-\sum_{i\in S}^{}\alpha_iy_i\bm{x}_i^{\mathrm{T}}\bm{x}_S\bigg)\]
					\end{enumerate}
				\subsection{核函数}
					\begin{itemize}
						\item 在现实任务中，原始样本空间可能不存在一个能正确划分两类样本的超平面，此时可将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。若原始空间是有限维，则必定存在这样一个高维特征空间。
						\item 设$\phi(\bm{x})$表示将$\bm{x}$映射后的特征向量。于是在特征空间中划分超平面所对应的模型可表示为$f(\bm{x})=\bm{w}^{\mathrm{T}}\phi(\bm{x})+b$。此时对偶问题约束条件不变，目标变为\[\max\limits_{\bm{\alpha}}\quad\sum_{i=1}^{m}\alpha_i-\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_i\alpha_jy_iy_j\phi(\bm{x}_i)^{\mathrm{T}}\phi(\bm{x}_j)\]直接在高维空间计算$\phi(\bm{x}_i)^{\mathrm{T}}\phi(\bm{x}_j)$很难，因此定义``核函数''：\[\kappa(\bm{x}_i,\bm{x}_j)=\langle\phi(\bm{x}_i),\phi(\bm{x}_j)\rangle=\phi(\bm{x}_i)^{\mathrm{T}}\phi(\bm{x}_j)\]由此``支持向量展式''为：\[f(\bm{x})=\bm{w}^{\mathrm{T}}\phi(\bm{x})+b=\sum_{i=1}^{m}\alpha_iy_i\phi(\bm{x}_i)^{\mathrm{T}}\phi(\bm{x})+b=\sum_{i=1}^{m}\alpha_iy_i\kappa(\bm{x},\bm{x}_i)+b\]
						\item 核函数的定理如下：\begin{theorem}
							令$\mathcal{X}$为输入空间，$\kappa(\cdot,\cdot)$是定义在$\mathcal{X}\times\mathcal{X}$上的对称函数，则$\kappa$是核函数当且仅当对于任意数据$D=\{\bm{x}_1,\bm{x}_2,\dots,\bm{x}_m\}$，``核矩阵''$\mathbf{K}$总是半定的。其中\[\mathbf{K}=\left[\begin{matrix}
							\kappa(\bm{x}_1,\bm{x}_2) & \cdots & \kappa(\bm{x},\bm{x}_j) & \cdots & \kappa(\bm{x},\bm{x}_m) \\
							\vdots & \ddots & \vdots & \ddots & \vdots \\
							\kappa(\bm{x}_i,\bm{x}_1) & \cdots & \kappa(\bm{x}_i,\bm{x}_j) & \cdots & \kappa(\bm{x}_i,\bm{x}_m) \\
							\vdots & \ddots & \vdots & \ddots & \vdots \\
							\kappa(\bm{x}_m, \bm{x}_1) & \cdots & \kappa(\bm{x}_m,\bm{x}_j) & \cdots & \kappa(\bm{x}_m,\bm{x}_m)
							\end{matrix}\right]\]
						\end{theorem}
						任何一个核函数都隐式地定义了一个``再生核希尔伯特空间''。\begin{framed}
							$\triangle$ 半正定矩阵的定义\begin{itemize}
								\item 广义：设$\bm{A}$是$n$阶方阵，如果对任何非零向量$\bm{X}$，都有$\bm{X}^{\mathrm{T}}\bm{A}\bm{X}\ge0$，则称$A$为半正定矩阵。
								\item 狭义（常用）：设$\bm{A}$为实对称矩阵，若对于每个非零实向量$\bm{X}$，都有$\bm{X}^{\mathrm{T}}\bm{A}\bm{X}\ge0$，则称$\bm{A}$为半正定矩阵，称$\bm{X}^{\mathrm{T}}\bm{AX}$为半正定二次型。
							\end{itemize}
							$\triangle$ 再生核希尔伯特空间等空间的概念可见文章：\href{http://users.umiacs.umd.edu/~hal/docs/daume04rkhs.pdf}{From Zero to Reproducing Kernel Hilbert Spaces in Twelve Pages or Less}。这玩意有点硬核OTZ
						\end{framed}
						\item 支持向量机的最大变数：核函数选择。可以使用常用的核函数并通过函数组合得到。\begin{center}
							\begin{tabular}{lll}
								\hline
								名称 & 表达式 & 参数\\ \hline
								线性核 & $\kappa(\bm{x}_i,\bm{x}_j)=\bm{x}_i^{\mathrm{T}}\bm{x}_j$ & \\
								多项式核 & $\kappa(\bm{x}_i,\bm{x}_j)=(\bm{x}_i^{\mathrm{T}}\bm{x}_j)^d$ & $d\ge1$为多项式的次数 \\
								高斯核 & $\kappa(\bm{x}_i,\bm{x}_j)=\mathrm{exp}(-\frac{\parallel \bm{x}_i-\bm{x}_j\parallel^2}{2\sigma^2})$ & $\sigma>0$为高斯核的带宽 \\
								拉普拉斯核 & $\kappa(\bm{x}_i,\bm{x}_j)=\mathrm{exp}(-\frac{\parallel\bm{x}_i-\bm{x}_j\parallel}{\sigma})$ & $\sigma>0$ \\
								Sigmoid核 & $\kappa(\bm{x}_i,\bm{x}_j)=\mathrm{tanh}(\beta\bm{x}_i^{\mathrm{T}}\bm{x}_j+\theta)$ & tanh为双曲正切函数，$\beta>0,\theta<0$ \\ \hline
							\end{tabular}
						\end{center}
						若$\kappa_1,\kappa_2$为核函数，则线性组合（任意正数$\gamma_1,\gamma_2$）$\gamma_1\kappa_1+\gamma_2\kappa_2$、直积$\kappa_1\otimes\kappa_2(\bm{x},\bm{z})=\kappa_1(\bm{x},\bm{z})\kappa_2(\bm{x},\bm{z})$也是核函数。对于任意函数$g(x)$，$\kappa(\bm{x},\bm{z})=g(\bm{x})\kappa_1(\bm{x},\bm{z})g(\bm{z})$也是核函数。
					\end{itemize}
				\subsection{软间隔与正则化}
					\begin{itemize}
						\item 在现实任务中很难确定合适的核函数$\rightarrow$允许支持向量机在一些样本上出错$\rightarrow$加入``软间隔''概念（区别于``硬间隔''）$\leftrightarrow$允许某些样本不满足约束$y_i(\bm{w}^{\mathrm{T}}\bm{x}_i+b)\ge1$
						\item 优化目标可改为\[\min\limits_{\bm{w},b}\quad\frac{1}{2}\parallel\bm{w}\parallel^2+C\sum_{i=1}^{m}\ell\big(y_i(\bm{w}^{\mathrm{T}}\bm{x}_i+b)-1\big)\]其中$C>0$为常数，$\ell$是损失函数，一般为``0/1损失函数''（负则输出1，否则输出0），也可以是替代损失函数，如\begin{itemize}
							\item hinge损失：$\ell_{hinge}(z)=\max(0, 1-z)$；
							\item 指数损失：$\ell_{exp}(z)=\exp(-z)$；
							\item 对率损失：$\ell_{log}(z)=\log(1+\exp(-z)).$
						\end{itemize}
						后续分析以hinge损失为例。
						\item 引入松弛变量$\xi_i\ge0$，则得到``软间隔支持向量机''：\begin{align*}
							& \min\limits_{\bm{w},b,\xi_i}\quad\frac{1}{2}\parallel\bm{w}\parallel^2+C\sum_{i=1}^{m}\xi_i \\
							& \mathrm{s.t.}\quad y_i(\bm{w}^{\mathrm{T}}+b)\ge1-\xi_i\\
							& \xi_i\ge0,i=1,2,\dots,m.
						\end{align*}
						仿照6.2节的步骤，先用拉格朗日乘子法得到拉格朗日函数（拉格朗日乘子为$\alpha_i\ge0,\mu_i\ge0$）：\[L(\bm{w},b,\bm{\alpha},\bm{\xi},\bm{\mu})=\frac{1}{2}\parallel\bm{w}\parallel^2+C\sum_{i=1}^{m}\xi_i+\sum_{i=1}^{m}\alpha_i(1-\xi_i-y_i(\bm{w}^{\mathrm{T}}\bm{x}_i+b))-\sum_{i=1}^{m}\mu_i\xi_i\]分别对$\bm{w},b,\xi_i$偏导令为零可得$\bm{w}=\sum_{i=1}^{m}\alpha_iy_i\bm{x}_i$、$0=\sum_{i=1}^{m}\alpha_iy_i$、$C=\alpha_i+\mu_i$。代入得到对偶问题\begin{align*}
							& \max\limits_{\bm{\alpha}}\quad\sum_{i=1}^{m}\alpha_i-\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_i\alpha_jy_iy_j\bm{x}_i^{\mathrm{T}}\bm{x}_j\\
							& \mathrm{s.t.}\quad\sum_{i=1}^{m}\alpha_iy_i=0\\
							& 0\le\alpha_i\le C,i=1,2,\dots,m.
						\end{align*}
						对此KKT条件要求：\[\left\{\begin{aligned}
						\alpha_i\ge0, \quad \mu_i\ge0,\\
						y_if(\bm{x}_i)-1+\xi_i\ge0,\\
						\alpha_i(y_if(\bm{x}_i)-1+\xi_i)=0,\\
						\xi_i\ge0,\quad \mu_i\xi_i=0
						\end{aligned}\right.\]若$\alpha_i=0$则该样本无影响，若$\alpha_i>0$则有$y_if(\bm{x}_i)=1-\xi_i$，该样本是支持向量。若$\alpha_i<C$，则$\mu_i>0$，故$\xi_i=0$，该样本位于最大间隔边界上。若$\alpha_i=C$则有$\mu_i=0$，此时若$\xi_i\le1$则该样本落在最大间隔内部，否则该样本被错误分类。软间隔支持向量机的最终模型仍然仅与支持向量有关。
						\item 共性：优化目标中，第一项用来描述划分超平面的间隔大小，另一项用于表述训练集上的误差。一般形式为\[\min\limits_{f}\Omega(f)+C\sum_{i=1}^{m}\ell(f(\bm{x}_i),y_i)\]其中\begin{itemize}
							\item 该形式可称为``正则化''问题。
							\item $\Omega(f)$：结构风险。描述模型$f$的某些性质，为引入领域知识和用户意图提供途径，并且可以削减假设空间，降低过拟合风险。它也被称为正则化项。
							\item $\sum_{i=1}^{m}\ell(f(\bm{x}_i),y_i)$：经验风险。描述模型与训练数据的契合程度。
							\item $C$：用于对二者进行折中。被称为正则化常数。
						\end{itemize}
					\end{itemize}
				\subsection{支持向量回归}
					\begin{itemize}
						\item 对于回归问题，支持向量回归（SVR）假设能够容忍$f(\bm{x})$与$y$之间最多有$\epsilon$的偏差，即差值大于$\epsilon$时才计算损失$\rightarrow$以$f(\bm{x})$为中心，构建一个宽度为$2\epsilon$的间隔带。落入此带的训练样本被认为是预测正确。
						\item SVR问题的目标：\[\min\limits_{\bm{w},b}\quad\frac{1}{2}\parallel\bm{w}\parallel^2+C\sum_{i=1}^{m}\ell_\epsilon(f(\bm{x}_i)-y_i)\]
					\end{itemize}
			\section{贝叶斯分类器}
			\section{集成学习}
			\section{聚类}
			\section{降维与度量学习}
			\section{特征选择与稀疏学习}
			\section{计算学习理论}
			\section{半监督学习}
			\section{概率图模型}
			\section{规则学习}
			\section{强化学习}
			
\end{document}